# ğŸ“˜ Large Document Q&A using LlamaIndex

A beginner-friendly **Large Document Question Answering (Q&A)** system built using **LlamaIndex** that demonstrates core concepts such as **Nodes**, **Chunking**, **Embeddings**, **Vector Indexing**, and **Query Engines** â€” without using any paid APIs.

This project focuses on **retrieval logic**, making it ideal for **learning and interviews**.

---

## ğŸš€ Features

- ğŸ“„ **Load large text documents** from a directory
- âœ‚ï¸ **Chunk documents** into manageable pieces (Nodes)
- ğŸ”¢ **Convert text into numerical vectors** using embeddings
- ğŸ§  **Store vectors** in a vector index
- ğŸ” **Retrieve the most relevant chunks** for a user query
- âŒ **No OpenAI / Paid API required** (fully offline)

---

## ğŸ§  Core Concepts Explained

### 1ï¸âƒ£ Documents
Raw text files loaded from the `data/` directory.

### 2ï¸âƒ£ Chunking
Large documents are split into smaller pieces to improve retrieval accuracy.

```python
SentenceSplitter(chunk_size=512, chunk_overlap=50)
```

### 3ï¸âƒ£ Nodes
A **Node** is a container that holds:
- Text chunk
- Metadata
- Embedding vector (numerical representation)

Think of it as:
```python
Node = { text + metadata + vector }
```

### 4ï¸âƒ£ Embeddings
Embeddings convert text into numbers (vectors) so that similarity can be calculated mathematically.

In this project we use:
```python
MockEmbedding(embed_dim=384)
```

âœ… No internet  
âœ… No API keys  
âœ… Ideal for learning and testing

### 5ï¸âƒ£ Vector Store Index
Stores all node embeddings and enables fast similarity search.

```python
VectorStoreIndex(nodes)
```

### 6ï¸âƒ£ Query Engine
Handles:
- Converting user query â†’ vector
- Finding similar nodes
- Returning relevant chunks

```python
index.as_query_engine(similarity_top_k=3)
```

---

## ğŸ“‚ Project Structure

```
large-doc-qa-llamaindex/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.txt          # Large document
â”‚
â”œâ”€â”€ app.py                  # Main application
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## ğŸ›  Installation

### 1ï¸âƒ£ Create Virtual Environment

```bash
conda create -n genai python=3.10
conda activate genai
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install llama-index
```

Or using requirements file:

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

1. **Add your `.txt` files** inside the `data/` folder

2. **Run the application:**

```bash
python app.py
```

3. **Ask questions** in the terminal:

```
Ask: What is LlamaIndex?
```

4. **Type `exit` to stop.**

---

## ğŸ“Œ Sample Output

```
Retrieved Nodes:

--- Node 1 ---
LlamaIndex is a data framework designed to connect LLMs with external data...

--- Node 2 ---
It provides tools for data ingestion, indexing, and querying...

--- Node 3 ---
The framework supports various data sources including documents, APIs...
```

---

## ğŸ” No API Keys Required

- âŒ OpenAI not used
- âŒ Hugging Face login not required
- âœ… **Fully offline project**

This makes it perfect for:
- ğŸ“ Learning RAG concepts
- ğŸ’¼ Interview preparation
- ğŸ§ª Testing retrieval logic
- ğŸ”’ Privacy-focused applications

---

## ğŸ¯ Learning Outcomes

After completing this project, you will understand:

âœ… Difference between **documents, nodes, and vectors**  
âœ… How **vector similarity search** works  
âœ… How **query engines** retrieve relevant context  
âœ… The role of **chunking** in information retrieval  
âœ… How **embeddings** enable semantic search  

---

## ğŸ”§ Configuration

### Adjust Chunk Size

Modify in `app.py`:

```python
text_splitter = SentenceSplitter(
    chunk_size=512,      # Increase for longer chunks (256-1024)
    chunk_overlap=50     # Adjust overlap (20-100)
)
```

### Change Top-K Results

Modify the number of retrieved chunks:

```python
query_engine = index.as_query_engine(
    similarity_top_k=3   # Change to retrieve more/fewer chunks (1-10)
)
```

### Use Different Embeddings

Replace `MockEmbedding` with real embeddings:

```python
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
```

---

## ğŸ“¦ requirements.txt

```
llama-index>=0.9.0
```

---

## ğŸ› Troubleshooting

### Issue: "No module named 'llama_index'"

**Solution:**
```bash
pip install llama-index
```

### Issue: "Empty data folder"

**Solution:**
- Ensure you have `.txt` files in the `data/` directory
- Check file permissions

### Issue: "No relevant chunks found"

**Solution:**
- Reduce `similarity_top_k` value
- Ensure your document contains relevant information
- Try rephrasing your query

---

## ğŸ”® Future Improvements

- [ ] Add **PDF document support**
- [ ] Use **HuggingFace** or **OpenAI** embeddings
- [ ] Integrate **FAISS** vector store
- [ ] Add **local LLM (Ollama)** for answer generation
- [ ] Build a **Streamlit UI**
- [ ] Add **multi-document support**
- [ ] Implement **query history**
- [ ] Add **evaluation metrics** (BLEU, ROUGE)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“š Learning Resources

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [Understanding RAG Systems](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [Vector Embeddings Explained](https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/)
- [Chunking Strategies](https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Vishal Yadav**  
Aspiring Data Scientist / GenAI Engineer  
ğŸ“ Pune, India

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/in/vishal-yadav-294138203/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black)](https://github.com/yadavJI-vishal)
[![Email](https://img.shields.io/badge/Email-Contact-red)](mailto:vy5068@gmail.com)

---

## â­ If you found this useful

Give this repository a â­ and share it on LinkedIn!

**Tags:** `#LlamaIndex` `#RAG` `#GenAI` `#VectorSearch` `#NLP` `#MachineLearning` `#Python`

---

