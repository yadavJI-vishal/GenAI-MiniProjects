**AI Text Generator & Sentiment Analyzer**

This project demonstrates practical usage of Generative AI and Natural Language Processing (NLP) using the Hugging Face Transformers library. It showcases how pre-trained transformer models can be used for text generation and sentiment classification with minimal code.

**ğŸš€ Features**

- Generate human-like text from a user-provided prompt
- Analyze sentiment (POSITIVE / NEGATIVE) of generated text
- Uses Hugging Face pipeline abstraction
- Command-line interface (CLI) based interaction
- Clean and modular Python code

**ğŸ§  Concepts Covered**

- Transformers library
- Tokenizers (handled internally by pipelines)
- Text generation using language models
- Sentiment classification using transformer-based models

**ğŸ› ï¸ Technologies Used**

- Python
- Hugging Face Transformers
- PyTorch
- Pre-trained transformer models

**AI Text Generator & Sentiment Analyzer/**

- â”œâ”€â”€ main.py              # Core application logic
- â”œâ”€â”€ requirements.txt     # Project dependencies
- â”œâ”€â”€ README.md            # Project documentation
- â””â”€â”€ .gitignore

**âš™ï¸ Installation**

Make sure you are using the correct Python environment.
pip install -r requirements.txt

**â–¶ï¸ How to Run**

python main.py

- You will be prompted to enter a text prompt.
- The application will:
  1. Generate text using a transformer model
  2. Analyze the sentiment of the generated text

**âœ¨ Example**

- Input Prompt: Artificial intelligence is changing the world
- Output
  1. Generated paragraph based on the prompt
  2. Sentiment label with confidence score
 
**ğŸ“Œ Learning Outcomes**

- Understand how transformer pipelines work
- Learn how tokenization is abstracted in NLP workflows
- Apply generative models and classifiers together
- Build a complete mini NLP application

**â­ Acknowledgements**

- Hugging Face Transformers
- Open-source NLP community
