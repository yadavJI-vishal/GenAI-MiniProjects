# ğŸ“„ Resume & Job Description Q&A Assistant using RAG

A **Retrieval-Augmented Generation (RAG)** based Questionâ€“Answering assistant that allows you to ask questions about a resume (PDF) and get accurate answers grounded strictly in the document content.

This project demonstrates an end-to-end RAG architecture optimized for efficiency and cost-effectiveness.

## ğŸš€ Project Highlights

* ğŸ“„ **Extracts text** from resume PDFs using PyPDF2.
* âœ‚ï¸ **Automatically chunks** large documents for better retrieval accuracy.
* ğŸ”¢ **Converts text into vector embeddings** using lightweight models.
* ğŸ§  **Performs semantic search** using vector similarity.
* ğŸ¤– **Uses Mistral-7B** to generate context-aware, grounded answers.
* ğŸ’° **No paid APIs required** (100% open-source).
* âš¡ **Runs on free Colab GPU** using 4-bit quantization.

---

## ğŸ§  What is RAG in this Project?

RAG (Retrieval-Augmented Generation) ensures the LLM provides factual answers by following this pipeline:

1. **User Query**
2. **Query Embedding** (Turning the question into numbers)
3. **Vector Search** (Retrieving the Top-K relevant chunks from the resume)
4. **Prompt Construction** (Combining the Context + Question)
5. **LLM Generation** (Generating the final answer)

ğŸ‘‰ **The LLM does NOT hallucinate** â€” it answers strictly using the retrieved resume content.

---

## ğŸ§± Architecture Overview

```mermaid
graph TD
    A[PDF Resume] --> B[Text Extraction - PyPDF2]
    B --> C[Chunking & Nodes - LlamaIndex]
    C --> D[Embeddings - MiniLM]
    D --> E[Vector Index]
    E --> F[Query Engine]
    F --> G[Mistral-7B Answer]

```

---

## ğŸ“‚ Project Structure

```text
RAG-Resume-QA/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Vishal-Yadav.pdf    # Your Resume PDF
â”‚
â”œâ”€â”€ app.py                  # Main application script
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation

```

---

## ğŸ› ï¸ Tech Stack

| Component | Tool / Framework |
| --- | --- |
| **Framework** | LlamaIndex |
| **Embeddings** | `sentence-transformers/all-MiniLM-L6-v2` |
| **LLM** | `Mistral-7B-Instruct-v0.3` |
| **Quantization** | BitsAndBytes (4-bit) |
| **PDF Parsing** | PyPDF2 |
| **Runtime** | Google Colab (T4 GPU) |

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Create Environment (Optional)

```bash
conda create -n rag python=3.10
conda activate rag

```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt

```

### 3ï¸âƒ£ (Optional) Hugging Face Login

Required if the model is gated or to access private repositories.

```python
from huggingface_hub import login
login()

```

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Upload Resume PDF

Place your resume inside the `data/` folder and update the path in `app.py`:

```python
PDF_PATH = "data/Vishal-Yadav.pdf"

```

### 2ï¸âƒ£ Run the Script

```bash
python app.py

```

---

## ğŸ’¬ Example Queries

* "List all the skills mentioned in this resume."
* "What is the email address in this resume?"
* "What technologies does the candidate work with?"
* "Summarize the professional experience."

### ğŸ“Œ Sample Output

> **ğŸ“ Query:** List all the skills mentioned in this resume.
> ## **âœ… Response (1.32s):**
> 
> 
> ## The candidate has experience in Python, SQL, Machine Learning, Data Analysis, Pandas, NumPy, and Deep Learning.
> 
> 

---

## âš™ï¸ Key Configurations

* **CHUNK_SIZE = 512**: Smaller chunks improve retrieval granularity.
* **CHUNK_OVERLAP = 50**: Ensures context is preserved across chunk boundaries.
* **TOP_K = 3**: Determines how many relevant snippets are sent to the LLM.

---

## ğŸ” Cost & Privacy

* âŒ **No OpenAI API**: Completely free to use.
* âŒ **No paid services**: Utilizes open-source models and free compute.
* âœ… **Fully offline**: After the initial model download, no data is sent to external APIs.
* âœ… **Privacy**: Your resume data stays within your specific environment.

---

## ğŸ¯ Learning Outcomes

* Understanding the internal mechanics of **Semantic Search**.
* Mastering **vector embeddings** and document indexing.
* Optimizing LLMs for **low-latency** on consumer/free hardware.
* Building production-ready RAG prompts.

---

## ğŸ”® Future Enhancements

* [ ] Add Job Description matching (Resume-JD Similarity Scoring).
* [ ] Integrate **FAISS** or **Pinecone** for larger scale retrieval.
* [ ] Support for `.docx` and multiple PDFs.
* [ ] Build a **Streamlit** user interface.
* [ ] Add **Reranking** (Cross-Encoders) for higher accuracy.

---

## ğŸ‘¨â€ğŸ’» Author

**Vishal Yadav** *Aspiring Data Scientist & GenAI Engineer* ğŸ“ Pune, India

â­ **If you found this useful, give the repository a star and feel free to fork or extend it!**
